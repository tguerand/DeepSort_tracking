{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading network.....\n",
      "Network successfully loaded\n",
      "video_detector.py:115: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  output = model(Variable(img, volatile = True), CUDA)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "2.0070059299468994\n",
      "FPS of the video is  0.50\n",
      "4.074826002120972\n",
      "FPS of the video is  0.49\n",
      "5.805264949798584\n",
      "FPS of the video is  0.52\n",
      "7.496501922607422\n",
      "FPS of the video is  0.53\n",
      "9.2307288646698\n",
      "FPS of the video is  0.54\n",
      "11.033302068710327\n",
      "FPS of the video is  0.54\n",
      "12.932623863220215\n",
      "FPS of the video is  0.54\n",
      "14.8627450466156\n",
      "FPS of the video is  0.54\n",
      "16.644646883010864\n",
      "FPS of the video is  0.54\n",
      "18.421317100524902\n",
      "FPS of the video is  0.54\n",
      "20.13289999961853\n",
      "FPS of the video is  0.55\n",
      "21.841994047164917\n",
      "FPS of the video is  0.55\n",
      "23.549713850021362\n",
      "FPS of the video is  0.55\n",
      "25.266607999801636\n",
      "FPS of the video is  0.55\n",
      "26.971935033798218\n",
      "FPS of the video is  0.56\n",
      "28.707814931869507\n",
      "FPS of the video is  0.56\n",
      "30.415971040725708\n",
      "FPS of the video is  0.56\n",
      "32.16923403739929\n",
      "FPS of the video is  0.56\n",
      "33.89777207374573\n",
      "FPS of the video is  0.56\n",
      "35.634921073913574\n",
      "FPS of the video is  0.56\n",
      "37.34043002128601\n",
      "FPS of the video is  0.56\n",
      "39.05588412284851\n",
      "FPS of the video is  0.56\n",
      "40.83496713638306\n",
      "FPS of the video is  0.56\n",
      "42.5550799369812\n",
      "FPS of the video is  0.56\n",
      "44.285529136657715\n",
      "FPS of the video is  0.56\n",
      "45.99232006072998\n",
      "FPS of the video is  0.57\n",
      "47.69443106651306\n",
      "FPS of the video is  0.57\n",
      "49.40954303741455\n",
      "FPS of the video is  0.57\n",
      "51.1211040019989\n",
      "FPS of the video is  0.57\n",
      "52.83954405784607\n",
      "FPS of the video is  0.57\n",
      "54.54396915435791\n",
      "FPS of the video is  0.57\n",
      "56.25497078895569\n",
      "FPS of the video is  0.57\n",
      "57.998892068862915\n",
      "FPS of the video is  0.57\n",
      "59.70400595664978\n",
      "FPS of the video is  0.57\n",
      "61.414551973342896\n",
      "FPS of the video is  0.57\n",
      "63.13809108734131\n",
      "FPS of the video is  0.57\n",
      "64.85281300544739\n",
      "FPS of the video is  0.57\n",
      "66.71651411056519\n",
      "FPS of the video is  0.57\n",
      "68.47139191627502\n",
      "FPS of the video is  0.57\n",
      "70.18797206878662\n",
      "FPS of the video is  0.57\n",
      "71.91577005386353\n",
      "FPS of the video is  0.57\n",
      "73.64445114135742\n",
      "FPS of the video is  0.57\n",
      "75.35616683959961\n",
      "FPS of the video is  0.57\n",
      "77.06173396110535\n",
      "FPS of the video is  0.57\n",
      "78.77641916275024\n",
      "FPS of the video is  0.57\n",
      "80.48777294158936\n",
      "FPS of the video is  0.57\n",
      "82.19215703010559\n",
      "FPS of the video is  0.57\n",
      "83.90303683280945\n",
      "FPS of the video is  0.57\n",
      "85.62580800056458\n",
      "FPS of the video is  0.57\n",
      "87.38215804100037\n",
      "FPS of the video is  0.57\n",
      "89.13986206054688\n",
      "FPS of the video is  0.57\n",
      "90.84286904335022\n",
      "FPS of the video is  0.57\n",
      "92.5565710067749\n",
      "FPS of the video is  0.57\n",
      "94.25180220603943\n",
      "FPS of the video is  0.57\n",
      "95.97496199607849\n",
      "FPS of the video is  0.57\n",
      "97.67877411842346\n",
      "FPS of the video is  0.57\n",
      "99.37190818786621\n",
      "FPS of the video is  0.57\n",
      "101.07006692886353\n",
      "FPS of the video is  0.57\n",
      "102.75280785560608\n",
      "FPS of the video is  0.57\n",
      "104.43806910514832\n",
      "FPS of the video is  0.57\n",
      "106.13225293159485\n",
      "FPS of the video is  0.57\n",
      "107.86924004554749\n",
      "FPS of the video is  0.57\n",
      "109.56371212005615\n",
      "FPS of the video is  0.58\n",
      "111.29571294784546\n",
      "FPS of the video is  0.58\n",
      "113.01729989051819\n",
      "FPS of the video is  0.58\n",
      "114.73083281517029\n",
      "FPS of the video is  0.58\n",
      "116.42825078964233\n",
      "FPS of the video is  0.58\n",
      "118.1177327632904\n",
      "FPS of the video is  0.58\n",
      "119.8012580871582\n",
      "FPS of the video is  0.58\n",
      "121.52830791473389\n",
      "FPS of the video is  0.58\n",
      "123.20758605003357\n",
      "FPS of the video is  0.58\n",
      "124.8928599357605\n",
      "FPS of the video is  0.58\n",
      "126.62431693077087\n",
      "FPS of the video is  0.58\n",
      "128.313805103302\n",
      "FPS of the video is  0.58\n",
      "130.02464509010315\n",
      "FPS of the video is  0.58\n",
      "131.73203301429749\n",
      "FPS of the video is  0.58\n",
      "133.50733017921448\n",
      "FPS of the video is  0.58\n",
      "135.2891981601715\n",
      "FPS of the video is  0.58\n",
      "137.3679130077362\n",
      "FPS of the video is  0.58\n",
      "139.19658017158508\n",
      "FPS of the video is  0.57\n",
      "140.9430170059204\n",
      "FPS of the video is  0.57\n",
      "142.65425300598145\n",
      "FPS of the video is  0.57\n",
      "144.74448204040527\n",
      "FPS of the video is  0.57\n",
      "146.6913139820099\n",
      "FPS of the video is  0.57\n"
     ]
    }
   ],
   "source": [
    "!python video_detector.py --video venice.mp4 --det det"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Darknet(\"cfg/yolov3.cfg\")\n",
    "model.load_weights(\"yolov3.weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 416, 416])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 18.4085,  16.3513, 127.6132,  ...,   0.6078,   0.5811,   0.5479],\n",
      "         [ 14.0165,  16.0823, 130.0517,  ...,   0.4999,   0.4629,   0.5191],\n",
      "         [ 13.0312,  18.1281, 363.9693,  ...,   0.5044,   0.6073,   0.4720],\n",
      "         ...,\n",
      "         [411.8825, 411.6734,   7.1775,  ...,   0.4133,   0.4810,   0.6057],\n",
      "         [412.1896, 411.8992,  15.8745,  ...,   0.5578,   0.4719,   0.4259],\n",
      "         [412.1518, 412.2277,  27.0367,  ...,   0.4285,   0.4651,   0.5174]]])\n"
     ]
    }
   ],
   "source": [
    "model = Darknet(\"cfg/yolov3.cfg\")\n",
    "inp = get_test_input()\n",
    "print(inp.shape)\n",
    "pred = model(inp, torch.cuda.is_available())\n",
    "print (pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = write_results(prediction, confidence=0.5, num_classes =80, nms_conf = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1421, 8])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10647, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(prediction[:,:,4] > confidence).float().unsqueeze(2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10647, 85])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10647, 85])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence = 0.5\n",
    "thres_prediction = prediction * ((prediction[:,:,4] > confidence).float().unsqueeze(2))\n",
    "def transform_box(b_x, b_y, b_w, b_h):\n",
    "    \"\"\"\n",
    "    transform box from (b_x, b_y, b_w, b_h to c_top_x, c_top_y, c_bot_x, c_bot_y\n",
    "    c_top_x, c_top_y : coordinates of top-left corner of box\n",
    "    c_bot_x, c_bot_y : coordinates of bottom-right corner of box\n",
    "    \"\"\"\n",
    "    c_top_x = b_x - b_w/2\n",
    "    c_top_y = b_y - b_h/2\n",
    "    \n",
    "    c_bot_x = b_x + b_w/2\n",
    "    c_bot_y = b_y + b_h/2\n",
    "    \n",
    "    \n",
    "    return c_top_x, c_top_y, c_bot_x, c_bot_y\n",
    "box_corner = thres_prediction.new(thres_prediction.shape)\n",
    "\n",
    "box_corner[:,:,0], box_corner[:,:,1], box_corner[:,:,2], box_corner[:,:,3] = transform_box(thres_prediction[:,:,0],thres_prediction[:,:,1],thres_prediction[:,:,2], thres_prediction[:,:,3])\n",
    "\n",
    "prediction[:,:,:4] = box_corner[:,:,:4]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = parse_cfg(\"cfg/yolov3.cfg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'convolutional', 'net', 'route', 'shortcut', 'upsample', 'yolo'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([x['type'] for x in dic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "##############################\n",
      "['6,7,8', '3,4,5', '0,1,2']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[dict_keys(['type', 'mask', 'anchors', 'classes', 'num', 'jitter', 'ignore_thresh', 'truth_thresh', 'random']),\n",
       " dict_keys(['type', 'mask', 'anchors', 'classes', 'num', 'jitter', 'ignore_thresh', 'truth_thresh', 'random']),\n",
       " dict_keys(['type', 'mask', 'anchors', 'classes', 'num', 'jitter', 'ignore_thresh', 'truth_thresh', 'random'])]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yolo_layers = [x for x in dic if x['type']=='yolo']\n",
    "print(len(yolo_layers))\n",
    "yolo_key =[ x.keys() for x in yolo_layers]\n",
    "print('##############################')\n",
    "print([ x['mask'] for x in yolo_layers])\n",
    "yolo_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n",
      "[dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'size', 'stride', 'pad', 'filters', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'size', 'stride', 'pad', 'filters', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'size', 'stride', 'pad', 'filters', 'activation']), dict_keys(['type', 'size', 'stride', 'pad', 'filters', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'size', 'stride', 'pad', 'filters', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'size', 'stride', 'pad', 'filters', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'size', 'stride', 'pad', 'filters', 'activation']), dict_keys(['type', 'size', 'stride', 'pad', 'filters', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'size', 'stride', 'pad', 'filters', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'size', 'stride', 'pad', 'filters', 'activation']), dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']), dict_keys(['type', 'batch_normalize', 'size', 'stride', 'pad', 'filters', 'activation']), dict_keys(['type', 'size', 'stride', 'pad', 'filters', 'activation'])]\n",
      "##############################\n",
      "##############################\n",
      "['1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1']\n"
     ]
    }
   ],
   "source": [
    "convolutional_layers = [x for x in dic if x['type']=='convolutional']\n",
    "print(len(convolutional_layers))\n",
    "convolutional_key =[ x.keys() for x in convolutional_layers]\n",
    "print(convolutional_key)\n",
    "print('##############################')\n",
    "print('##############################')\n",
    "batch_layers = [x for x in  convolutional_layers if 'batch_normalize' in (list(x.keys()))]\n",
    "print([ x['batch_normalize'] for x in batch_layers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "[dict_keys(['type', 'from', 'activation']), dict_keys(['type', 'from', 'activation']), dict_keys(['type', 'from', 'activation']), dict_keys(['type', 'from', 'activation']), dict_keys(['type', 'from', 'activation']), dict_keys(['type', 'from', 'activation']), dict_keys(['type', 'from', 'activation']), dict_keys(['type', 'from', 'activation']), dict_keys(['type', 'from', 'activation']), dict_keys(['type', 'from', 'activation']), dict_keys(['type', 'from', 'activation']), dict_keys(['type', 'from', 'activation']), dict_keys(['type', 'from', 'activation']), dict_keys(['type', 'from', 'activation']), dict_keys(['type', 'from', 'activation']), dict_keys(['type', 'from', 'activation']), dict_keys(['type', 'from', 'activation']), dict_keys(['type', 'from', 'activation']), dict_keys(['type', 'from', 'activation']), dict_keys(['type', 'from', 'activation']), dict_keys(['type', 'from', 'activation']), dict_keys(['type', 'from', 'activation']), dict_keys(['type', 'from', 'activation'])]\n",
      "##############################\n",
      "['-3', '-3', '-3', '-3', '-3', '-3', '-3', '-3', '-3', '-3', '-3', '-3', '-3', '-3', '-3', '-3', '-3', '-3', '-3', '-3', '-3', '-3', '-3']\n",
      "##############################\n",
      "['linear', 'linear', 'linear', 'linear', 'linear', 'linear', 'linear', 'linear', 'linear', 'linear', 'linear', 'linear', 'linear', 'linear', 'linear', 'linear', 'linear', 'linear', 'linear', 'linear', 'linear', 'linear', 'linear']\n"
     ]
    }
   ],
   "source": [
    "shortcut_layers = [x for x in dic if x['type']=='shortcut']\n",
    "print(len(shortcut_layers))\n",
    "shortcut_key =[ x.keys() for x in shortcut_layers]\n",
    "print(shortcut_key)\n",
    "print('##############################')\n",
    "print([ x['from'] for x in shortcut_layers])\n",
    "print('##############################')\n",
    "print([ x['activation'] for x in shortcut_layers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([ x['activation'] for x in shortcut_layers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[dict_keys(['type', 'stride']), dict_keys(['type', 'stride'])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upsample_layers = [x for x in dic if x['type']=='upsample']\n",
    "print(len(upsample_layers))\n",
    "upsample_key =[ x.keys() for x in upsample_layers]\n",
    "upsample_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[84, 87, 96, 99]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "route_index = [i for i in range(len(dic)) if dic[i]['type']=='route']\n",
    "route_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['-4'], ['-1', ' 61'], ['-4'], ['-1', ' 36']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "route_layers = [x for x in dic if x['type']=='route']\n",
    "print(len(route_layers))\n",
    "route_key =[ x.keys() for x in route_layers]\n",
    "route_l = [x['layers'].split(',') for x in route_layers]\n",
    "route_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'size', 'stride', 'pad', 'filters', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'size', 'stride', 'pad', 'filters', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'size', 'stride', 'pad', 'filters', 'activation']),\n",
       " dict_keys(['type', 'size', 'stride', 'pad', 'filters', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'size', 'stride', 'pad', 'filters', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'size', 'stride', 'pad', 'filters', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'size', 'stride', 'pad', 'filters', 'activation']),\n",
       " dict_keys(['type', 'size', 'stride', 'pad', 'filters', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'size', 'stride', 'pad', 'filters', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'size', 'stride', 'pad', 'filters', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'filters', 'size', 'stride', 'pad', 'activation']),\n",
       " dict_keys(['type', 'batch_normalize', 'size', 'stride', 'pad', 'filters', 'activation']),\n",
       " dict_keys(['type', 'size', 'stride', 'pad', 'filters', 'activation'])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_key =[ x.keys() for x in conv_layers]\n",
    "conv_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'net',\n",
       "  'batch': '64',\n",
       "  'subdivisions': '16',\n",
       "  'width': '608',\n",
       "  'height': '608',\n",
       "  'channels': '3',\n",
       "  'momentum': '0.9',\n",
       "  'decay': '0.0005',\n",
       "  'angle': '0',\n",
       "  'saturation': '1.5',\n",
       "  'exposure': '1.5',\n",
       "  'hue': '.1',\n",
       "  'learning_rate': '0.001',\n",
       "  'burn_in': '1000',\n",
       "  'max_batches': '500200',\n",
       "  'policy': 'steps',\n",
       "  'steps': '400000,450000',\n",
       "  'scales': '.1,.1'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '32',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '64',\n",
       "  'size': '3',\n",
       "  'stride': '2',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '32',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '64',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'size': '3',\n",
       "  'stride': '2',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '64',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '64',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '3',\n",
       "  'stride': '2',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'size': '3',\n",
       "  'stride': '2',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '1024',\n",
       "  'size': '3',\n",
       "  'stride': '2',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '1024',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '1024',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '1024',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '1024',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'filters': '1024',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'filters': '1024',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'filters': '1024',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'filters': '255',\n",
       "  'activation': 'linear'},\n",
       " {'type': 'yolo',\n",
       "  'mask': '6,7,8',\n",
       "  'anchors': '10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326',\n",
       "  'classes': '80',\n",
       "  'num': '9',\n",
       "  'jitter': '.3',\n",
       "  'ignore_thresh': '.7',\n",
       "  'truth_thresh': '1',\n",
       "  'random': '1'},\n",
       " {'type': 'route', 'layers': '-4'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'upsample', 'stride': '2'},\n",
       " {'type': 'route', 'layers': '-1, 61'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'filters': '512',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'filters': '512',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'filters': '512',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'filters': '255',\n",
       "  'activation': 'linear'},\n",
       " {'type': 'yolo',\n",
       "  'mask': '3,4,5',\n",
       "  'anchors': '10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326',\n",
       "  'classes': '80',\n",
       "  'num': '9',\n",
       "  'jitter': '.3',\n",
       "  'ignore_thresh': '.7',\n",
       "  'truth_thresh': '1',\n",
       "  'random': '1'},\n",
       " {'type': 'route', 'layers': '-4'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'upsample', 'stride': '2'},\n",
       " {'type': 'route', 'layers': '-1, 36'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'filters': '256',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'filters': '256',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'filters': '256',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'filters': '255',\n",
       "  'activation': 'linear'},\n",
       " {'type': 'yolo',\n",
       "  'mask': '0,1,2',\n",
       "  'anchors': '10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326',\n",
       "  'classes': '80',\n",
       "  'num': '9',\n",
       "  'jitter': '.3',\n",
       "  'ignore_thresh': '.7',\n",
       "  'truth_thresh': '1',\n",
       "  'random': '1'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
